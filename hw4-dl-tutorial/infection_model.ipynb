{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling for infection diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup, get data & import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # Enable progress bar for pandas (change apply to progress_apply)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wd/pkw1ts416gsg2fjyp1rgznqc0000gn/T/ipykernel_50102/122200257.py:16: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prescriptions_df = pd.read_csv('PRESCRIPTIONS.csv').set_index('ROW_ID')\n"
     ]
    }
   ],
   "source": [
    "MIMIC_3_DIR = '../mimic/mimic-iii-clinical-database-1.4'\n",
    "os.chdir(MIMIC_3_DIR)\n",
    "\n",
    "diagnoses_df = pd.read_csv('DIAGNOSES_ICD.csv').set_index('ROW_ID')\n",
    "diagnoses_df.columns = diagnoses_df.columns.str.lower()\n",
    "\n",
    "notes_df = pd.read_csv('NOTEEVENTS.csv', low_memory=False).set_index('ROW_ID')\n",
    "notes_df.columns = notes_df.columns.str.lower()\n",
    "\n",
    "microbio_df = pd.read_csv('MICROBIOLOGYEVENTS.csv').set_index('ROW_ID')\n",
    "microbio_df.columns = microbio_df.columns.str.lower()\n",
    "\n",
    "patients_df = pd.read_csv('PATIENTS.csv').set_index('ROW_ID')\n",
    "patients_df.columns = patients_df.columns.str.lower()\n",
    "\n",
    "prescriptions_df = pd.read_csv('PRESCRIPTIONS.csv').set_index('ROW_ID')\n",
    "prescriptions_df.columns = prescriptions_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(651047, 4)\n",
      "Duplicates in diagnoses_df: 0\n",
      "(2083180, 10)\n",
      "Duplicates in notes_df: 4863\n",
      "(631726, 15)\n",
      "Duplicates in microbio_df: 18414\n",
      "(46520, 7)\n",
      "Duplicates in patients_df: 0\n",
      "(4156450, 18)\n",
      "Duplicates in prescriptions_df: 236072\n"
     ]
    }
   ],
   "source": [
    "# Keep only unique diagnoses\n",
    "print(diagnoses_df.shape)\n",
    "print(\"Duplicates in diagnoses_df:\", diagnoses_df.duplicated().sum())\n",
    "diagnoses_df = diagnoses_df.drop_duplicates()\n",
    "\n",
    "# Keep only unique notes\n",
    "print(notes_df.shape)\n",
    "print(\"Duplicates in notes_df:\", notes_df.duplicated().sum())\n",
    "notes_df = notes_df.drop_duplicates()\n",
    "\n",
    "# Keep only unique microbiology events\n",
    "print(microbio_df.shape)\n",
    "print(\"Duplicates in microbio_df:\", microbio_df.duplicated().sum())\n",
    "microbio_df = microbio_df.drop_duplicates()\n",
    "\n",
    "# Keep only unique patients\n",
    "print(patients_df.shape)\n",
    "print(\"Duplicates in patients_df:\", patients_df.duplicated().sum())\n",
    "patients_df = patients_df.drop_duplicates()\n",
    "\n",
    "# Keep only unique prescriptions\n",
    "print(prescriptions_df.shape)\n",
    "print(\"Duplicates in prescriptions_df:\", prescriptions_df.duplicated().sum())\n",
    "prescriptions_df = prescriptions_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & set patient ages for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age function\n",
    "def calculate_age(dob, dod):\n",
    "    dob_date = datetime.strptime(dob, \"%Y-%m-%d %H:%M:%S\")\n",
    "    if pd.isna(dod):\n",
    "        return None\n",
    "    dod_date = datetime.strptime(dod, \"%Y-%m-%d %H:%M:%S\")\n",
    "    age = (dod_date - dob_date).days // 365\n",
    "    return age\n",
    "\n",
    "# Apply calculate_age function to create \"age\" column\n",
    "patients_df['age'] = patients_df.apply(lambda row: calculate_age(row['dob'], row['dod']), axis=1)\n",
    "\n",
    "# Filter out rows with age greater than or equal to 120\n",
    "filtered_patients_df = patients_df[patients_df['age'] < 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify common bloodborne pathogens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common blood infection codes\n",
    "infection_codes = ['0380', '03810', '0382', '0383', '03842', '03843']\n",
    "# Filter for only infection codes\n",
    "infection_df = diagnoses_df[diagnoses_df['icd9_code'].isin(infection_codes)].copy()\n",
    "\n",
    "infection_types = {   \n",
    "    \"0380\": \"Streptococcal septicemia\",\n",
    "    \"03810\": \"Staphylococcal septicemia, unspecified\",\n",
    "    \"0382\": \"Pneumococcal septicemia [Streptococcus pneumoniae septicemia]\",\n",
    "    \"0383\": \"Septicemia due to anaerobes\",\n",
    "    \"03842\": \"Septicemia due to escherichia coli [E. coli]\",\n",
    "    \"03843\": \"Septicemia due to pseudomonas\",\n",
    "}\n",
    "\n",
    "# Map infection types to infection codes\n",
    "infection_df['infection_type'] = infection_df['icd9_code'].map(infection_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and process Infection, Notes, & Patients dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate notes by subject_id\n",
    "aggregated_notes_df = notes_df.groupby('subject_id')['text'].unique().reset_index()\n",
    "aggregated_notes_df.rename(columns={'text': 'unique_notes'}, inplace=True)\n",
    "# Ensure 'unique_notes' is a string\n",
    "aggregated_notes_df['unique_notes'] = aggregated_notes_df['unique_notes'].apply(lambda x: ' '.join(x) if isinstance(x, np.ndarray) else x)\n",
    "# Limit notes to 50K characters\n",
    "aggregated_notes_df['unique_notes'] = aggregated_notes_df['unique_notes'].apply(lambda x: x[:5000] if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# merge notes with infection data\n",
    "merged_inf_notes_df = pd.merge(infection_df, aggregated_notes_df, on='subject_id', how='inner')\n",
    "\n",
    "# merge notes with infection data with patients\n",
    "merged_inf_notes_pats_df = pd.merge(merged_inf_notes_df, filtered_patients_df, on='subject_id', how='inner')\n",
    "\n",
    "# Keep only relevant features from merged data\n",
    "merged_inf_notes_pats_df = merged_inf_notes_pats_df[['subject_id', 'infection_type', 'unique_notes', 'gender', 'expire_flag', 'age']]\n",
    "\n",
    "# Drop rows with missing age\n",
    "merged_inf_notes_pats_df.dropna(subset=['age'], inplace=True)\n",
    "\n",
    "# Drop duplicate notes\n",
    "# merged_inf_notes_pats_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "# Because dataset is large, sample 1% of the data\n",
    "# merged_inf_notes_pats_df = merged_inf_notes_pats_df.sample(frac=0.01, random_state=42)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission Date:  [**2114-7-8**]       Discharge Date:  [**2114-7-16**]\n",
      "\n",
      "Date of Birth:   [**2069-7-16**]       Sex:  M\n",
      "\n",
      "Service:  Trauma\n",
      "\n",
      "HISTORY OF PRESENT ILLNESS:  1. Closed head injury consisting\n",
      "of a left frontal subarachnoid hemorrhage which was stable.\n",
      "2. Left elbow fracture.  3. Left scapula fracture.  4. Left\n",
      "distal radioulnar joint separation.  5. Altered mental status\n",
      "secondary to #1.\n",
      "\n",
      "PHYSICAL EXAMINATION:  Examination on discharge includes in\n",
      "general the patient is wearing a cervical collar and appears\n",
      "alert and oriented x 1 and is in no acute distress.  HEENT\n",
      "shows the pupils to be equal, round, and reactive to light,\n",
      "extraocular motion is intact.  Neck examination shows the\n",
      "trachea is midline, no jugular venous distension is noted.\n",
      "Cardiovascularly he has regular rate and rhythm.  Pulmonary\n",
      "showed that the lungs are clear to auscultation bilaterally,\n",
      "no wheezes are heard.  Abdomen is soft, nondistended and\n",
      "nontender.  Bowel sounds are normal and active.  Extremities\n",
      "show no cyanosis, clubbing or edema, 2+ pulses are felt\n",
      "throughout.  Genitourinary examination shows a Foley catheter\n",
      "in place, otherwise normal.  Skin is warm and dry.\n",
      "Neurologic examination shows that the patient is able to\n",
      "follow all commands, moving all extremities normally.\n",
      "Sensation appears intact in all extremities.  There are no\n",
      "cerebellar signs.\n",
      "\n",
      "LABORATORY DATA:  During his hospital stay laboratory and\n",
      "x-ray findings include a CT scan of his abdomen which was\n",
      "negative for any traumatic injury.  A chest x-ray was\n",
      "negative for any traumatic injury.  A CT scan of his chest\n",
      "showed a left scapular fracture.\n",
      "\n",
      "Pertinent laboratory findings on admission included a white\n",
      "count of 16.4, an hematocrit of 40, platelet count of 306, a\n",
      "urine toxicology which was positive for benzodiazepines, a\n",
      "lactate was 2.2.  PT was 12.8, PTT 21, INR 1.1, fibrinogen\n",
      "328.  Electrolytes on admission included sodium of 146,\n",
      "potassium 4.4, chloride 103, bicarbonate 29, BUN 13,\n",
      "creatinine 0.9, glucose 122.  A pelvic x-ray showed no\n",
      "fracture upon admission.\n",
      "\n",
      "A CT of his head on the day of admission showed a left\n",
      "frontoparietal subarachnoid hemorrhage.  A CT of his cervical\n",
      "spine showed a preliminary result negative for any fractures.\n",
      "Flexion-extension view x-rays of the cervical spine upon\n",
      "flexion and upon extension were negative for any signs of\n",
      "injury to the cervical spine.\n",
      "\n",
      "HOSPITAL COURSE:  Upon admission the patient was awake,\n",
      "somnolent and uncooperative.  His vital signs included a\n",
      "temperature of 98.4, heart rate of 107, blood pressure\n",
      "140/palpable, respiratory rate of 18, breathing 97% on room\n",
      "air.  His physical examination on admission included an\n",
      "examination of the extremities showing 2+ pulses throughout,\n",
      "sensation being intact.  His left arm was tender and there\n",
      "was deformity of the left arm which was splinted.  His back\n",
      "showed no stepoffs but some mild thoracic tenderness\n",
      "therefore the patient was placed on cervical spine\n",
      "precautions and log roll precautions.  His pelvis was stable\n",
      "and nontender.  His rectal examination had normal tone\n",
      "without any gross blood.  His abdomen was soft, nondistended\n",
      "and nontender with normal bowel sounds.  His chest was stable\n",
      "and nontender without any abrasions, bruises or ecchymoses.\n",
      "His lungs were clear to auscultation bilaterally.\n",
      "\n",
      "The patient was admitted to the trauma surgery intensive care\n",
      "unit for neurological checks.  A neurosurgery consultation\n",
      "was obtained and a head scan was repeated the following\n",
      "morning.  This patient had brought films with him.  CT scan\n",
      "of his cervical spine from an outside hospital was reported\n",
      "to be negative for fracture.  An orthopedic consultation was\n",
      "obtained due to his left arm pain.  The x-rays of his left\n",
      "arm showed a left radial head fracture and this arm was\n",
      "splinted by orthopedics.\n",
      "\n",
      "During the patient's stay in the trauma intensive care unit,\n",
      "he remained on cervical spine and log roll precautions but\n",
      "made progress and remained hemodynamically stable.  He did\n",
      "not require intubation.  A repeat scan of his head after a\n",
      "reported witnessed fall was negative for any change from the\n",
      "previous study.  His right frontoparietal subarachnoid\n",
      "hemorrhage appeared to be stable.  The patient's blood\n",
      "pressure remained under control per neurosurgery orders.  The\n",
      "patient's scapular fracture was determined to be\n",
      "nonoperative.  The patient's radial head fracture was kept in\n",
      "a posterior splint for five to seven days, that is, the\n",
      "splint will be removed today upon discharge and gentle range\n",
      "of motion elbow exercises will ensue.\n",
      "\n",
      "The patient remained stable and was transferred to the floor,\n",
      "that is the unit CC6A, where his mental status remained\n",
      "altered likely secondary to his closed head injury.  The\n",
      "patient's vital signs remained stable.  He did not spike any\n",
      "fevers and his blood pressure and heart rate remained within\n",
      "normal limits throughout his stay on the floor.\n",
      "\n",
      "Medications while in house included Ativan p.r.n.,\n",
      "hydralazine and metoprolol to control blood pressure,\n",
      "morphine for pain contr\n",
      "5000\n",
      "1\n",
      "10746\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "aggregated_notes_df.head()\n",
    "# print one entire note to check\n",
    "print(aggregated_notes_df['unique_notes'][350])\n",
    "# count characters in note\n",
    "print(len(aggregated_notes_df['unique_notes'][350]))\n",
    "# find note with highest char count\n",
    "print(aggregated_notes_df['unique_notes'].apply(len).idxmax())\n",
    "# find note with lowest char count\n",
    "print(aggregated_notes_df['unique_notes'].apply(len).idxmin())\n",
    "# determine what type of object is in the 'unique_notes' column\n",
    "print(type(aggregated_notes_df['unique_notes'][350]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process & merge Prescriptions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3920378, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(567, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up prescription data\n",
    "print(prescriptions_df.shape)\n",
    "prescriptions_df = prescriptions_df[['subject_id', 'drug_name_generic', 'formulary_drug_cd', 'prod_strength', 'dose_val_rx', 'dose_unit_rx', 'form_val_disp', 'form_unit_disp', 'route']]\n",
    "prescriptions_df = prescriptions_df.dropna(subset=['drug_name_generic'])\n",
    "\n",
    "# Aggregate prescriptions by subject_id\n",
    "aggregated_prescriptions_df = prescriptions_df.groupby('subject_id')['drug_name_generic'].unique().reset_index()\n",
    "aggregated_prescriptions_df.rename(columns={'drug_name_generic': 'unique_prescriptions'}, inplace=True)\n",
    "\n",
    "# merge notes, infections, patients, and prescriptions\n",
    "data_df = pd.merge(merged_inf_notes_pats_df, aggregated_prescriptions_df, on='subject_id', how='inner')\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jefdewitt/miniconda3/envs/new_env/lib/python3.10/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    }
   ],
   "source": [
    "# Load SciSpacy Model (en_core_sci_md)\n",
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "\n",
    "def get_note_embedding(text):\n",
    "    \"\"\"Computes sentence embedding by averaging word vectors in the note.\"\"\"\n",
    "    try:\n",
    "        # If text is a numpy array, convert to string\n",
    "        if isinstance(text, np.ndarray):\n",
    "            text = ' '.join(text)\n",
    "\n",
    "        # Process text with SciSpacy model\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Extract word vectors for all words that have embeddings\n",
    "        vectors = [token.vector for token in doc if token.has_vector]\n",
    "\n",
    "        # If the sentence has no word vectors (rare case), return zeros\n",
    "        if len(vectors) == 0:\n",
    "            return np.zeros((300,))\n",
    "\n",
    "        # Compute sentence embedding (average of word embeddings)\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        return np.zeros((300,))  # Return a zero vector if error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 567/567 [21:15<00:00,  2.25s/it]    \n"
     ]
    }
   ],
   "source": [
    "# Apply embedding extraction\n",
    "data_df[\"sentence_embeddings\"] = data_df[\"unique_notes\"].progress_apply(get_note_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/pkw1ts416gsg2fjyp1rgznqc0000gn/T/ipykernel_50102/4202550653.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# change column name to unique_prescriptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# data_df.rename(columns={'test_unique_prescriptions': 'unique_prescriptions'}, inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# data_df.drop(columns=['text_embeddings'], inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_prescriptions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new_env/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "data_df.head()\n",
    "\n",
    "# drop test_unique_prescriptions and another_test_unique_prescriptions columns\n",
    "# data_df.drop(columns=['unique_prescriptions', 'another_test_unique_prescriptions'], inplace=True)\n",
    "# data_df.dropna(subset=['test_unique_prescriptions', 'another_test_unique_prescriptions'], inplace=True)\n",
    "# change column name to unique_prescriptions\n",
    "# data_df.rename(columns={'test_unique_prescriptions': 'unique_prescriptions'}, inplace=True)\n",
    "# data_df.drop(columns=['text_embeddings'], inplace=True)\n",
    "\n",
    "# get type of object in 'unique_prescriptions' column\n",
    "print(type(data_df['unique_prescriptions'][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "# Load dataset\n",
    "# df = pd.read_csv(\"your_data.csv\")  # Replace with actual data\n",
    "\n",
    "# Encode categorical variables\n",
    "le_infection = LabelEncoder()\n",
    "data_df['infection_type'] = le_infection.fit_transform(data_df['infection_type'])\n",
    "\n",
    "data_df['gender'] = data_df['gender'].map({'M': 0, 'F': 1})  # Convert gender to binary\n",
    "\n",
    "# Encode prescriptions as multi-label binary\n",
    "mlb = MultiLabelBinarizer()\n",
    "# df['unique_prescriptions'] = df['unique_prescriptions'].apply(eval)  # Convert string lists to actual lists\n",
    "data_df['unique_prescriptions'] = data_df['unique_prescriptions'].progress_apply(lambda x: eval(x) if isinstance(x, str) else x)  # Convert string lists to actual lists\n",
    "prescription_matrix = mlb.fit_transform(data_df['unique_prescriptions'])\n",
    "\n",
    "# Convert text data to SciSpacy embeddings\n",
    "data_df['text_embeddings'] = data_df['unique_notes'].apply(get_note_embedding)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
